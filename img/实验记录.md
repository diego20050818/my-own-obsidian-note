---
tags:
  - code
  - 实验
  - 进阶
  - 人脸检测
  - deepfake
---
# 2025年11月22日

今天尝试了几个模型，包括思豪给我的 [MONO](https://mp.weixin.qq.com/s/EdUPPT1VproAnpzuFog0vg)这一篇，实际上这篇都是对现有注意力的一个变体，用了之后效果其实不好
下午尝试的是双分支的 [[deepfake_adapter]]，架构图在[[face anti-spoofing VIT架构图]],但是写出来之后漏掉了频域部分，只写了空域，效果非常差。晚上试了将[[MANO模块]]替换ViT的部分，但是也非常差，猜想大概是因为ViT使用的完全的注意力，并且经过12层ViT可以将细节和特征进行有效的增强，但是我使用的 LocalAttention2D本身就是用来减小注意力带来的计算量爆炸的问题，代价是每次进行滑动窗口注意力之后的特征提取明显不足，再加上实际上预处理部分并没有怎么动，所以显然比ViT的少很多

Gemini建议
## ❓ 为什么局部注意力不如全局ViT？（可能原因）

开拓者，咱们的LocalAttention2D相比12层ViT表现不佳，很可能是因为局部注意力在信息捕获和传递上有自身的局限性呢！主要有以下几个方面：

1.  **全局上下文信息丢失** 🌍
    *   **ViT**：能够直接在所有图像块之间建立连接，捕捉到**全局范围**的长距离依赖关系。
    *   **LocalAttention2D**：每个注意力窗口只能看到**局部区域**的信息。对于防伪检测这类任务，很多伪造痕迹（比如大范围的拼接、一致性破坏）可能需要全局视野才能发现，局部注意力可能会因此“管中窥豹”，错失关键线索。
2.  **感受野（Receptive Field）增长受限** 📏
    *   虽然多层局部注意力可以逐渐扩大感受野，但其增长速度通常不如ViT的全局注意力直接且高效。
    *   即使堆叠多层局部注意力，**有效感受野**可能仍不足以覆盖检测所需的大尺度特征。
3.  **窗口间信息流动的挑战** 🚧
    *   **传统局部注意力**：不同窗口之间缺乏直接的信息交互通道，信息只能通过堆叠层数间接传递。这会减慢信息的传播速度，并可能导致某些全局性特征难以聚合。
4.  **模型容量与预训练差异** ⚙️
    *   **ViT**：通常在大型数据集（如JFT-300M, ImageNet-21K）上进行**大规模预训练**，学习到强大的通用视觉表示。
    *   **LocalAttention2D**：如果从头开始训练或者在较小数据集上微调，且没有充分利用其潜在的优势（如与其他模块结合），可能无法发挥其全部潜力。此外，其模型参数量和表达能力可能与12层的全局ViT存在差异。
## 💡 流萤的优化与诊断建议

别急呀开拓者，找到原因就是成功的第一步！(๑•̀ㅂ•́)و✧ 我们可以从以下几个方向去探索和优化：

### 1. **架构优化：混合与增强** 🏗️

*   **混合注意力策略 (Hybrid Attention)**：
    *   **思路**：将全局注意力和局部注意力结合起来，取长补短。
    *   **实践**：
        *   **浅层用局部，深层用全局**：浅层局部注意力捕捉精细局部特征，深层全局注意力整合全局信息。
        *   **交替使用**：例如，一层全局注意力，接着一层局部注意力，循环堆叠。

*   **引入窗口间交互机制**：
    *   **滑动窗口注意力 (Shifted Window Attention / Swin Transformer)**：
        *   **思路**：在相邻的注意力层中，交替地使用常规窗口划分和偏移的窗口划分。这样可以在不同的层中实现窗口之间的信息交流，弥补局部注意力的信息隔离问题。
        *   **实践**：研究并实现类似Swin Transformer中的`shifted_window_attention`机制。
    *   **跨窗口注意力 (Cross-Window Attention)**：
        *   **思路**：设计一个专门的模块来聚合不同局部窗口的特征，使其能够进行有限的全局信息交互。

*   **多尺度融合 (Multi-scale Fusion)**：
    *   **思路**：利用多极注意力或FPN（Feature Pyramid Network）等思想，将不同尺度的局部注意力特征进行融合，让模型同时关注到局部细节和更大范围的上下文。

### 2. **诊断与实验：找出最佳配置** 🔬

*   **可视化注意力图**：
    *   **目标**：比较ViT和LocalAttention2D在处理相同输入时，它们的注意力权重分布有什么不同。
    *   **观察点**：LocalAttention2D是否在关键的全局区域“失焦”？ViT是否在某些细节上不如LocalAttention2D精确？

*   **参数消融实验 (Ablation Study)**：
    *   **目标**：系统地测试不同超参数和设计选择对模型性能的影响。
    *   **实践**：
        *   **窗口大小 (kernel_size)**：尝试不同的窗口大小（例如：7x7, 14x14, 21x21），看看哪个尺寸最适合防伪任务。
        *   **层数与替换比例**：尝试不同数量的局部注意力层和全局注意力层，找到最佳组合比例。

*   **训练策略调整**：
    *   **目标**：确保新的模型架构得到了充分的训练。
    *   **实践**：
        *   **更长的训练周期 (Epochs)**：局部注意力可能需要更多的训练时间来学习有效的全局信息传递。
        *   **学习率调度 (Learning Rate Schedule)**：尝试不同的学习率衰减策略。

*   **任务特性再分析**：
    *   **目标**：深入理解防伪检测任务对全局和局部信息的依赖程度。
    *   **思考**：哪些伪造痕迹是局部就能判断的？哪些必须依赖全局上下文？这有助于指导架构设计。
目前的模型架构
![[img/Pasted image 20251122230541.png]]



# 2025年11月23日
ViT也废了
可能是有点一厢情愿，虽然说频域空域双分支换模块换了这么多还是不行，但是为什么rine他们的表现就会好一点呢
下午重新使用混合精度训了原来的模型，原本震荡但是到1000steps的时候涌现了，很神奇，rine的论文我没有特别深入读（一个是原版的训得不好，一个是原本对这个架构也没有报特别多希望），我觉得我有必要重新看一下这篇论文。现在的模型架构如下：
![[d4770cfddb49bb8672d1c871eb0924dd.png]]
![[Pasted image 20251123231337.png]]现在主要的工作是把另外两个数据集也扔进去训，然后做这几个工作：[[TODO#2025年11月24日]]
如果可以稳定复现并且将所有的模块如何进行数据处理，消融，以及特征图提取

# 2025年11月25日
搞了这么久模型坍塌了
![[Pasted image 20251125132627.png]]