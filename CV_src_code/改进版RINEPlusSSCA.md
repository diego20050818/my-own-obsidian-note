---
tags:
  - code
  - è®¡ç®—æœºè§†è§‰
  - äººè„¸æ£€æµ‹
  - è¿›é˜¶
---
from:[[RINEPlusSSCA source code]]
# ğŸ¯ å¤šå°ºåº¦å±‚æ¬¡åŒ–Transformeræ¶æ„ (MS-HiT)

## ğŸ“Š æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "è¾“å…¥å±‚"
        A[è¾“å…¥å›¾åƒ<br/>224Ã—224Ã—3]
    end
    
    subgraph "å¤šå°ºåº¦ç‰¹å¾æå–"
        B[å›¾åƒé‡‘å­—å¡”ç”Ÿæˆ<br/>3ä¸ªå°ºåº¦]
        C[å°ºåº¦1: 224Ã—224]
        D[å°ºåº¦2: 112Ã—112]
        E[å°ºåº¦3: 56Ã—56]
    end
    
    subgraph "å±‚æ¬¡åŒ–Transformerä¸»å¹²"
        F[é˜¶æ®µ1: 56Ã—56Ã—96<br/>Swin-Tå—Ã—2]
        G[é˜¶æ®µ2: 28Ã—28Ã—192<br/>Swin-Tå—Ã—2]
        H[é˜¶æ®µ3: 14Ã—14Ã—384<br/>Swin-Tå—Ã—6]
        I[é˜¶æ®µ4: 7Ã—7Ã—768<br/>Swin-Tå—Ã—2]
    end
    
    subgraph "å¤šåˆ†æ”¯ç‰¹å¾èåˆ"
        J[å…¨å±€è¯­ä¹‰åˆ†æ”¯<br/>CLS Tokenèšåˆ]
        K[å±€éƒ¨ç»†èŠ‚åˆ†æ”¯<br/>ç©ºé—´æ³¨æ„åŠ›]
        L[é¢‘åŸŸç‰¹å¾åˆ†æ”¯<br/>DCTå˜æ¢]
    end
    
    subgraph "äº¤å‰æ³¨æ„åŠ›èåˆ"
        M[å¤šå¤´äº¤å‰æ³¨æ„åŠ›<br/>Q:å…¨å±€, K/V:å±€éƒ¨]
        N[é—¨æ§ç‰¹å¾èåˆ]
        O[æ®‹å·®è¿æ¥]
    end
    
    subgraph "è¾“å‡ºå±‚"
        P[åˆ†ç±»å¤´<br/>768â†’512â†’2]
        Q[ç‰¹å¾è¡¨ç¤º<br/>å¯¹æ¯”å­¦ä¹ ]
    end
    
    A --> B
    B --> C
    B --> D
    B --> E
    C --> F
    D --> G
    E --> H
    F --> J
    G --> K
    H --> L
    J --> M
    K --> M
    L --> M
    M --> N
    N --> O
    O --> P
    O --> Q
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style J fill:#e8f5e8
    style K fill:#fff3e0
    style L fill:#ffebee
    style M fill:#e0f2f1
    style P fill:#fce4ec
```

## ğŸ§© æ ¸å¿ƒè®¾è®¡æ€æƒ³

### 1. å¤šå°ºåº¦é‡‘å­—å¡”è¾“å…¥
- **å°ºåº¦1 (224Ã—224)**: é«˜åˆ†è¾¨ç‡ï¼Œä¿ç•™ç»†èŠ‚ä¿¡æ¯
- **å°ºåº¦2 (112Ã—112)**: ä¸­ç­‰åˆ†è¾¨ç‡ï¼Œå¹³è¡¡è®¡ç®—å’Œç²¾åº¦
- **å°ºåº¦3 (56Ã—56)**: ä½åˆ†è¾¨ç‡ï¼Œæå–å…¨å±€è¯­ä¹‰

### 2. å±‚æ¬¡åŒ–Transformerè®¾è®¡
å€Ÿé‰´Swin-Tçš„å±‚æ¬¡åŒ–ç»“æ„ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰ä¸åŒçš„æ„Ÿå—é‡ï¼š
- **é˜¶æ®µ1**: å±€éƒ¨ç‰¹å¾æå–
- **é˜¶æ®µ2**: ä¸­ç­‰èŒƒå›´ç‰¹å¾
- **é˜¶æ®µ3**: é•¿è·ç¦»ä¾èµ–å…³ç³»
- **é˜¶æ®µ4**: å…¨å±€è¯­ä¹‰ç†è§£

### 3. å¤šåˆ†æ”¯ç‰¹å¾èåˆ
- **å…¨å±€è¯­ä¹‰åˆ†æ”¯**: å…³æ³¨æ•´ä½“å›¾åƒå†…å®¹
- **å±€éƒ¨ç»†èŠ‚åˆ†æ”¯**: æ•æ‰çº¹ç†å’Œè¾¹ç¼˜ä¿¡æ¯
- **é¢‘åŸŸç‰¹å¾åˆ†æ”¯**: åˆ†æé¢‘ç‡åŸŸç‰¹å¾æ¨¡å¼

## ğŸ’» ä»£ç å®ç°

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MultiScaleHierarchicalTransformer(nn.Module):
    """
    å¤šå°ºåº¦å±‚æ¬¡åŒ–Transformeræ¶æ„
    
    è®¾è®¡ç†å¿µï¼š
    - å¤šå°ºåº¦è¾“å…¥ï¼šå¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒ
    - å±‚æ¬¡åŒ–ç‰¹å¾ï¼šä»å±€éƒ¨åˆ°å…¨å±€çš„ç‰¹å¾æå–
    - å¤šåˆ†æ”¯èåˆï¼šç»“åˆè¯­ä¹‰ã€ç»†èŠ‚å’Œé¢‘åŸŸä¿¡æ¯
    """
    
    def __init__(self, num_classes=2, img_size=224, embed_dim=96, depths=[2, 2, 6, 2], 
                 num_heads=[3, 6, 12, 24], window_size=7, use_scales=[0.5, 0.25]):
        super().__init__()
        
        self.img_size = img_size
        self.use_scales = use_scales  # å¤šå°ºåº¦æ¯”ä¾‹ [0.5, 0.25]
        
        # ==================== å¤šå°ºåº¦è¾“å…¥å¤„ç† ====================
        self.scale_encoders = nn.ModuleList()
        for scale in use_scales:
            encoder = SwinTransformerEncoder(
                img_size=int(img_size * scale),
                embed_dim=embed_dim,
                depths=depths,
                num_heads=num_heads,
                window_size=window_size
            )
            self.scale_encoders.append(encoder)
        
        # åŸå§‹å°ºåº¦ç¼–ç å™¨
        self.original_encoder = SwinTransformerEncoder(
            img_size=img_size,
            embed_dim=embed_dim,
            depths=depths,
            num_heads=num_heads,
            window_size=window_size
        )
        
        # ==================== å¤šåˆ†æ”¯ç‰¹å¾æå– ====================
        self.global_branch = GlobalSemanticBranch(embed_dim * 8)  # é˜¶æ®µ4è¾“å‡ºç»´åº¦
        self.local_branch = LocalDetailBranch(embed_dim * 4)     # é˜¶æ®µ3è¾“å‡ºç»´åº¦
        self.frequency_branch = FrequencyDomainBranch(embed_dim * 2)  # é˜¶æ®µ2è¾“å‡ºç»´åº¦
        
        # ==================== äº¤å‰æ³¨æ„åŠ›èåˆ ====================
        self.cross_attention_fusion = CrossAttentionFusion(
            global_dim=embed_dim * 8,
            local_dim=embed_dim * 4,
            freq_dim=embed_dim * 2,
            out_dim=embed_dim * 8
        )
        
        # ==================== è¾“å‡ºå¤´ ====================
        self.classifier = nn.Sequential(
            nn.LayerNorm(embed_dim * 8),
            nn.Linear(embed_dim * 8, 512),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(512, num_classes)
        )
        
        self.feature_head = nn.Linear(embed_dim * 8, 512)  # ç”¨äºå¯¹æ¯”å­¦ä¹ çš„ç‰¹å¾è¡¨ç¤º
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        å‚æ•°:
            x: è¾“å…¥å›¾åƒ [batch_size, 3, H, W]
        
        è¿”å›:
            logits: åˆ†ç±»logits [batch_size, num_classes]
            features: ç‰¹å¾è¡¨ç¤º [batch_size, 512]
        """
        batch_size = x.shape[0]
        
        # ==================== å¤šå°ºåº¦ç‰¹å¾æå– ====================
        multi_scale_features = []
        
        # åŸå§‹å°ºåº¦
        orig_features = self.original_encoder(x)
        multi_scale_features.append(orig_features)
        
        # å¤šå°ºåº¦å¤„ç†
        for i, scale in enumerate(self.use_scales):
            scaled_x = F.interpolate(x, scale_factor=scale, mode='bilinear', align_corners=False)
            scale_features = self.scale_encoders[i](scaled_x)
            scale_features = self._upsample_features(scale_features, orig_features[-1].shape[-2:])
            multi_scale_features.append(scale_features)
        
        # ==================== å¤šåˆ†æ”¯ç‰¹å¾æå– ====================
        stage4_features = [feat[-1] for feat in multi_scale_features]  # é˜¶æ®µ4ç‰¹å¾
        stage3_features = [feat[-2] for feat in multi_scale_features]  # é˜¶æ®µ3ç‰¹å¾
        stage2_features = [feat[-3] for feat in multi_scale_features]  # é˜¶æ®µ2ç‰¹å¾
        
        global_features = self.global_branch(stage4_features)
        local_features = self.local_branch(stage3_features)
        freq_features = self.frequency_branch(stage2_features)
        
        # ==================== äº¤å‰æ³¨æ„åŠ›èåˆ ====================
        fused_features = self.cross_attention_fusion(
            global_features, local_features, freq_features
        )
        
        # ==================== è¾“å‡º ====================
        logits = self.classifier(fused_features)
        features = self.feature_head(fused_features)
        
        return logits, features
    
    def _upsample_features(self, features, target_size):
        """ä¸Šé‡‡æ ·ç‰¹å¾åˆ°ç›®æ ‡å°ºå¯¸"""
        upsampled_features = []
        for feat in features:
            if feat.dim() == 4:  # ç©ºé—´ç‰¹å¾
                upsampled = F.interpolate(feat, size=target_size, mode='bilinear', align_corners=False)
            else:  # åºåˆ—ç‰¹å¾
                upsampled = feat  # ä¿æŒåŸæ ·
            upsampled_features.append(upsampled)
        return upsampled_features

class SwinTransformerEncoder(nn.Module):
    """ç®€åŒ–çš„Swin Transformerç¼–ç å™¨"""
    
    def __init__(self, img_size=224, embed_dim=96, depths=[2, 2, 6, 2], 
                 num_heads=[3, 6, 12, 24], window_size=7):
        super().__init__()
        
        self.stages = nn.ModuleList()
        
        # é˜¶æ®µ1: 56Ã—56Ã—96
        stage1 = nn.Sequential(*[
            SwinTransformerBlock(embed_dim, num_heads[0], window_size)
            for _ in range(depths[0])
        ])
        self.stages.append(stage1)
        
        # é˜¶æ®µ2: 28Ã—28Ã—192
        stage2 = nn.Sequential(*[
            SwinTransformerBlock(embed_dim * 2, num_heads[1], window_size)
            for _ in range(depths[1])
        ])
        self.stages.append(stage2)
        
        # é˜¶æ®µ3: 14Ã—14Ã—384
        stage3 = nn.Sequential(*[
            SwinTransformerBlock(embed_dim * 4, num_heads[2], window_size)
            for _ in range(depths[2])
        ])
        self.stages.append(stage3)
        
        # é˜¶æ®µ4: 7Ã—7Ã—768
        stage4 = nn.Sequential(*[
            SwinTransformerBlock(embed_dim * 8, num_heads[3], window_size)
            for _ in range(depths[3])
        ])
        self.stages.append(stage4)
    
    def forward(self, x):
        features = []
        current_x = x
        
        for stage in self.stages:
            current_x = stage(current_x)
            features.append(current_x)
        
        return features

class GlobalSemanticBranch(nn.Module):
    """å…¨å±€è¯­ä¹‰åˆ†æ”¯ - å…³æ³¨æ•´ä½“å›¾åƒå†…å®¹"""
    
    def __init__(self, dim):
        super().__init__()
        self.attention_pool = nn.AdaptiveAvgPool2d(1)
        self.proj = nn.Linear(dim, dim)
        
    def forward(self, features_list):
        pooled_features = []
        for feat in features_list:
            pooled = self.attention_pool(feat).view(feat.size(0), -1)
            pooled = self.proj(pooled)
            pooled_features.append(pooled)
        
        fused = torch.stack(pooled_features, dim=1).mean(dim=1)
        return fused

class LocalDetailBranch(nn.Module):
    """å±€éƒ¨ç»†èŠ‚åˆ†æ”¯ - ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶"""
    
    def __init__(self, dim):
        super().__init__()
        self.spatial_attention = SpatialAttention(dim)
        
    def forward(self, features_list):
        attended_features = []
        for feat in features_list:
            attended = self.spatial_attention(feat)
            pooled = F.adaptive_avg_pool2d(attended, 1).view(attended.size(0), -1)
            attended_features.append(pooled)
        
        fused = torch.stack(attended_features, dim=1).mean(dim=1)
        return fused

class FrequencyDomainBranch(nn.Module):
    """é¢‘åŸŸç‰¹å¾åˆ†æ”¯ - DCTå˜æ¢åˆ†æ"""
    
    def __init__(self, dim):
        super().__init__()
        self.dct_layer = DCTLayer()
        self.freq_proj = nn.Linear(dim, dim)
        
    def forward(self, features_list):
        freq_features = []
        for feat in features_list:
            freq_feat = self.dct_layer(feat)
            proj_feat = self.freq_proj(freq_feat.view(freq_feat.size(0), -1))
            freq_features.append(proj_feat)
        
        fused = torch.stack(freq_features, dim=1).mean(dim=1)
        return fused

class CrossAttentionFusion(nn.Module):
    """äº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—"""
    
    def __init__(self, global_dim, local_dim, freq_dim, out_dim):
        super().__init__()
        
        self.global_proj = nn.Linear(global_dim, out_dim)
        self.local_proj = nn.Linear(local_dim, out_dim)
        self.freq_proj = nn.Linear(freq_dim, out_dim)
        
        self.cross_attn = nn.MultiheadAttention(out_dim, num_heads=8, batch_first=True)
        
        self.gate = nn.Sequential(
            nn.Linear(out_dim * 3, out_dim),
            nn.Sigmoid()
        )
        
    def forward(self, global_feat, local_feat, freq_feat):
        q = self.global_proj(global_feat).unsqueeze(1)  # [B, 1, D]
        k = self.local_proj(local_feat).unsqueeze(1)    # [B, 1, D]
        v = self.freq_proj(freq_feat).unsqueeze(1)      # [B, 1, D]
        
        attended, _ = self.cross_attn(q, k, v)
        attended = attended.squeeze(1)
        
        concat_features = torch.cat([global_feat, local_feat, freq_feat], dim=1)
        gate_weights = self.gate(concat_features)
        
        fused = gate_weights * attended + (1 - gate_weights) * global_feat
        
        return fused

# è¾…åŠ©ç»„ä»¶å®šä¹‰
class SwinTransformerBlock(nn.Module):
    """ç®€åŒ–çš„Swin Transformerå—"""
    def __init__(self, dim, num_heads, window_size):
        super().__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)
        self.norm2 = nn.LayerNorm(dim)
        self.mlp = nn.Sequential(
            nn.Linear(dim, dim * 4),
            nn.GELU(),
            nn.Linear(dim * 4, dim)
        )
    
    def forward(self, x):
        # ç®€åŒ–å®ç°
        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]
        x = x + self.mlp(self.norm2(x))
        return x

class SpatialAttention(nn.Module):
    """ç©ºé—´æ³¨æ„åŠ›æ¨¡å—"""
    def __init__(self, dim):
        super().__init__()
        self.conv = nn.Conv2d(dim, dim, 3, padding=1)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        attention = self.sigmoid(self.conv(x))
        return x * attention

class DCTLayer(nn.Module):
    """DCTé¢‘åŸŸå˜æ¢å±‚"""
    def __init__(self):
        super().__init__()
    
    def forward(self, x):
        # ç®€åŒ–å®ç°
        return torch.fft.rfft2(x, norm='ortho').abs()

# æµ‹è¯•ä»£ç 
def test_model():
    model = MultiScaleHierarchicalTransformer(num_classes=2)
    x = torch.randn(2, 3, 224, 224)
    logits, features = model(x)
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"åˆ†ç±»è¾“å‡º: {logits.shape}")
    print(f"ç‰¹å¾è¡¨ç¤º: {features.shape}")
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

if __name__ == "__main__":
    test_model()
```

## ğŸ”— ç›¸å…³æ¦‚å¿µé“¾æ¥

- [[é‡‘å­—å¡”å’Œç‰¹å¾é‡‘å­—å¡”ç¬”è®°]] - å¤šå°ºåº¦å¤„ç†åŸºç¡€
- [[Swan-T]] - å±‚æ¬¡åŒ–Transformerè®¾è®¡
- [[RINEPlusSSCA source code]] - å¤šåˆ†æ”¯èåˆåº”ç”¨
- [[åŒåˆ†æ”¯å†™æ³•]] - åŒåˆ†æ”¯æ¶æ„è®¾è®¡
- [[Vision Transformer (ViT) æ¨¡å‹è¯¦è§£]] - TransformeråŸºç¡€

## ğŸ¯ åº”ç”¨åœºæ™¯

- **æ·±åº¦ä¼ªé€ æ£€æµ‹**: å¤šå°ºåº¦ç‰¹å¾æœ‰åŠ©äºæ•æ‰ä¸åŒç²’åº¦çš„ä¼ªé€ ç—•è¿¹
- **äººè„¸é˜²ä¼ª**: ç»“åˆå…¨å±€è¯­ä¹‰å’Œå±€éƒ¨ç»†èŠ‚æé«˜æ£€æµ‹ç²¾åº¦
- **å›¾åƒåˆ†ç±»**: å¤šåˆ†æ”¯èåˆå¢å¼ºç‰¹å¾è¡¨ç¤ºèƒ½åŠ›
- **ç›®æ ‡æ£€æµ‹**: å±‚æ¬¡åŒ–ç‰¹å¾é€‚åˆå¤šå°ºåº¦ç›®æ ‡æ£€æµ‹

## ğŸ’¡ åˆ›æ–°ç‚¹æ€»ç»“

1. **å¤šå°ºåº¦é‡‘å­—å¡”è¾“å…¥**: åŒæ—¶å¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒ
2. **å±‚æ¬¡åŒ–Transformer**: ä»å±€éƒ¨åˆ°å…¨å±€çš„ç‰¹å¾æå–
3. **å¤šåˆ†æ”¯ç‰¹å¾èåˆ**: è¯­ä¹‰ã€ç»†èŠ‚ã€é¢‘åŸŸä¿¡æ¯äº’è¡¥
4. **äº¤å‰æ³¨æ„åŠ›èåˆ**: è‡ªé€‚åº”ç‰¹å¾æƒé‡åˆ†é…
5. **é—¨æ§èåˆæœºåˆ¶**: åŠ¨æ€è°ƒæ•´å„åˆ†æ”¯è´¡çŒ®åº¦

