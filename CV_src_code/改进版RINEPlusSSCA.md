---
tags:
  - code
  - è®¡ç®—æœºè§†è§‰
  - äººè„¸æ£€æµ‹
  - è¿›é˜¶
---
---

tags:
  - code
  - è®¡ç®—æœºè§†è§‰
  - äººè„¸æ£€æµ‹
  - ç´¢è²å°”ç®—å­
  - å¤šå°ºåº¦é‡‘å­—å¡”
---
from:[[æ”¹è¿›ç‰ˆRINEPlusSSCA]]
from:[[ç´¢è²å°”ç®—å­ç¬”è®°]]

# ğŸ¯ ç´¢è²å°”å¢å¼ºçš„å¤šå°ºåº¦é‡‘å­—å¡”RINEæ¶æ„

## ğŸ“Š æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "è¾“å…¥å±‚"
        A[è¾“å…¥å›¾åƒ<br/>224Ã—224Ã—3]
    end
    
    subgraph "ç´¢è²å°”è¾¹ç¼˜å¢å¼º"
        B[ç´¢è²å°”ç®—å­<br/>è®¡ç®—è¾¹ç¼˜å¹…å€¼å’Œæ–¹å‘]
        C[è¾¹ç¼˜å¼•å¯¼ç‰¹å¾<br/>å¢å¼ºç¯¡æ”¹åŒºåŸŸ]
    end
    
    subgraph "å¤šå°ºåº¦é‡‘å­—å¡”"
        D[å°ºåº¦1: 224Ã—224<br/>é«˜åˆ†è¾¨ç‡ç»†èŠ‚]
        E[å°ºåº¦2: 112Ã—112<br/>ä¸­ç­‰åˆ†è¾¨ç‡]
        F[å°ºåº¦3: 56Ã—56<br/>ä½åˆ†è¾¨ç‡è¯­ä¹‰]
    end
    
    subgraph "RINEä¸»å¹²ç½‘ç»œ"
        G[æ®‹å·®å—1<br/>64é€šé“]
        H[æ®‹å·®å—2<br/>128é€šé“]
        I[æ®‹å·®å—3<br/>256é€šé“]
        J[æ®‹å·®å—4<br/>512é€šé“]
    end
    
    subgraph "ç‰¹å¾èåˆ"
        K[å¤šå°ºåº¦ç‰¹å¾æ‹¼æ¥]
        L[æ³¨æ„åŠ›åŠ æƒèåˆ]
        M[å…¨å±€æ± åŒ–]
    end
    
    subgraph "è¾“å‡ºå±‚"
        N[åˆ†ç±»å¤´<br/>çœŸä¼ªåˆ¤æ–­]
        O[ç‰¹å¾è¡¨ç¤º<br/>å¯¹æ¯”å­¦ä¹ ]
    end
    
    A --> B
    B --> C
    C --> D
    C --> E
    C --> F
    D --> G
    E --> H
    F --> I
    G --> K
    H --> K
    I --> K
    K --> L
    L --> M
    M --> N
    M --> O
    
    style B fill:#e1f5fe
    style C fill:#f3e5f5
    style D fill:#e8f5e8
    style E fill:#fff3e0
    style F fill:#ffebee
    style L fill:#e0f2f1
```

## ğŸ’» å®Œæ•´ä»£ç å®ç°

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

class SobelEnhancedRINE(nn.Module):
    """
    ç´¢è²å°”å¢å¼ºçš„å¤šå°ºåº¦é‡‘å­—å¡”RINEæ¶æ„
    
    è®¾è®¡ç†å¿µï¼š
    - ç´¢è²å°”è¾¹ç¼˜å¢å¼ºï¼šçªå‡ºç¯¡æ”¹è¾¹ç•Œç‰¹å¾
    - å¤šå°ºåº¦é‡‘å­—å¡”ï¼šæ•æ‰ä¸åŒç²’åº¦çš„ä¼ªé€ ç—•è¿¹
    - RINEæ®‹å·®ç½‘ç»œï¼šç¨³å®šçš„ç‰¹å¾æå–
    - æ³¨æ„åŠ›èåˆï¼šè‡ªé€‚åº”ç‰¹å¾æƒé‡åˆ†é…
    """
    
    def __init__(self, num_classes=2, img_size=224, base_channels=64, 
                 pyramid_scales=[1.0, 0.5, 0.25], use_sobel=True):
        super().__init__()
        
        self.img_size = img_size
        self.pyramid_scales = pyramid_scales
        self.use_sobel = use_sobel
        
        # ==================== ç´¢è²å°”è¾¹ç¼˜å¢å¼º ====================
        if use_sobel:
            self.sobel_enhancer = SobelEdgeEnhancer()
        
        # ==================== å¤šå°ºåº¦ç‰¹å¾æå– ====================
        self.pyramid_encoders = nn.ModuleList()
        for scale in pyramid_scales:
            encoder = RINEEncoder(
                in_channels=3,
                base_channels=base_channels,
                num_blocks=[2, 2, 2, 2],
                scale_factor=scale
            )
            self.pyramid_encoders.append(encoder)
        
        # ==================== ç‰¹å¾èåˆæ¨¡å— ====================
        self.feature_fusion = MultiScaleFusion(
            channel_list=[base_channels * 8, base_channels * 4, base_channels * 2],
            out_channels=base_channels * 8
        )
        
        # ==================== è¾“å‡ºå¤´ ====================
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(base_channels * 8, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
        
        self.feature_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(base_channels * 8, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        å‚æ•°:
            x: è¾“å…¥å›¾åƒ [batch_size, 3, H, W]
        
        è¿”å›:
            logits: åˆ†ç±»logits [batch_size, num_classes]
            features: ç‰¹å¾è¡¨ç¤º [batch_size, 512]
            edge_maps: è¾¹ç¼˜ç‰¹å¾å›¾ [å¯é€‰]
        """
        batch_size = x.shape[0]
        
        # ==================== ç´¢è²å°”è¾¹ç¼˜å¢å¼º ====================
        if self.use_sobel:
            edge_enhanced = self.sobel_enhancer(x)
            # åŸå§‹å›¾åƒ + è¾¹ç¼˜å¢å¼ºç‰¹å¾
            enhanced_input = x + 0.3 * edge_enhanced
        else:
            enhanced_input = x
        
        # ==================== å¤šå°ºåº¦ç‰¹å¾æå– ====================
        multi_scale_features = []
        
        for i, (scale, encoder) in enumerate(zip(self.pyramid_scales, self.pyramid_encoders)):
            if scale == 1.0:
                # åŸå§‹å°ºåº¦
                scale_input = enhanced_input
            else:
                # ç¼©æ”¾å°ºåº¦
                target_size = (int(self.img_size * scale), int(self.img_size * scale))
                scale_input = F.interpolate(enhanced_input, size=target_size, 
                                          mode='bilinear', align_corners=False)
            
            # æå–ç‰¹å¾
            scale_features = encoder(scale_input)
            multi_scale_features.append(scale_features)
        
        # ==================== å¤šå°ºåº¦ç‰¹å¾èåˆ ====================
        fused_features = self.feature_fusion(multi_scale_features)
        
        # ==================== è¾“å‡º ====================
        logits = self.classifier(fused_features)
        features = self.feature_head(fused_features)
        
        if self.use_sobel:
            edge_maps = self.sobel_enhancer.get_edge_maps(x)
            return logits, features, edge_maps
        else:
            return logits, features

class SobelEdgeEnhancer(nn.Module):
    """ç´¢è²å°”è¾¹ç¼˜å¢å¼ºæ¨¡å—"""
    
    def __init__(self, kernel_size=3, sigma=1.0):
        super().__init__()
        
        # ç´¢è²å°”å·ç§¯æ ¸
        self.sobel_x, self.sobel_y = self._create_sobel_kernels(kernel_size)
        
        # é«˜æ–¯å¹³æ»‘ï¼ˆå¯é€‰ï¼‰
        self.gaussian_blur = GaussianBlur(sigma=sigma)
        
        # è¾¹ç¼˜å¢å¼ºå·ç§¯
        self.edge_conv = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 3, 3, padding=1),
            nn.Sigmoid()
        )
    
    def _create_sobel_kernels(self, kernel_size):
        """åˆ›å»ºç´¢è²å°”å·ç§¯æ ¸"""
        if kernel_size == 3:
            sobel_x = torch.tensor([[-1, 0, 1],
                                   [-2, 0, 2], 
                                   [-1, 0, 1]], dtype=torch.float32).view(1, 1, 3, 3)
            sobel_y = torch.tensor([[-1, -2, -1],
                                   [0, 0, 0],
                                   [1, 2, 1]], dtype=torch.float32).view(1, 1, 3, 3)
        else:
            # æ”¯æŒå…¶ä»–æ ¸å°ºå¯¸
            sobel_x, sobel_y = self._create_general_sobel(kernel_size)
        
        return nn.Parameter(sobel_x, requires_grad=False), nn.Parameter(sobel_y, requires_grad=False)
    
    def _create_general_sobel(self, kernel_size):
        """åˆ›å»ºé€šç”¨ç´¢è²å°”æ ¸"""
        kernel = torch.zeros(kernel_size, kernel_size)
        center = kernel_size // 2
        
        for i in range(kernel_size):
            for j in range(kernel_size):
                dx = j - center
                dy = i - center
                kernel[i, j] = dx / (dx*dx + dy*dy + 1e-6)
        
        sobel_x = kernel.unsqueeze(0).unsqueeze(0)
        sobel_y = kernel.t().unsqueeze(0).unsqueeze(0)
        return sobel_x, sobel_y
    
    def forward(self, x):
        """è¾¹ç¼˜å¢å¼ºå‰å‘ä¼ æ’­"""
        batch_size, channels, height, width = x.shape
        
        # é«˜æ–¯å¹³æ»‘ï¼ˆå‡å°‘å™ªå£°ï¼‰
        smoothed = self.gaussian_blur(x)
        
        # è®¡ç®—æ¢¯åº¦å¹…å€¼
        gradient_maps = []
        for c in range(channels):
            channel_data = smoothed[:, c:c+1, :, :]
            
            # ç´¢è²å°”å·ç§¯
            grad_x = F.conv2d(channel_data, self.sobel_x, padding=1)
            grad_y = F.conv2d(channel_data, self.sobel_y, padding=1)
            
            # æ¢¯åº¦å¹…å€¼
            magnitude = torch.sqrt(grad_x**2 + grad_y**2 + 1e-6)
            gradient_maps.append(magnitude)
        
        # åˆå¹¶é€šé“æ¢¯åº¦
        edge_magnitude = torch.cat(gradient_maps, dim=1)
        
        # å½’ä¸€åŒ–
        edge_magnitude = edge_magnitude / (edge_magnitude.max() + 1e-6)
        
        # è¾¹ç¼˜å¢å¼º
        enhanced_edges = self.edge_conv(edge_magnitude)
        
        return enhanced_edges
    
    def get_edge_maps(self, x):
        """è·å–è¾¹ç¼˜ç‰¹å¾å›¾ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
        with torch.no_grad():
            batch_size, channels, height, width = x.shape
            edge_maps = []
            
            for c in range(channels):
                channel_data = x[:, c:c+1, :, :]
                grad_x = F.conv2d(channel_data, self.sobel_x, padding=1)
                grad_y = F.conv2d(channel_data, self.sobel_y, padding=1)
                magnitude = torch.sqrt(grad_x**2 + grad_y**2 + 1e-6)
                edge_maps.append(magnitude)
            
            return torch.cat(edge_maps, dim=1)

class RINEEncoder(nn.Module):
    """RINEæ®‹å·®ç¼–ç å™¨"""
    
    def __init__(self, in_channels=3, base_channels=64, num_blocks=[2, 2, 2, 2], scale_factor=1.0):
        super().__init__()
        
        self.scale_factor = scale_factor
        
        # åˆå§‹å·ç§¯å±‚
        self.stem = nn.Sequential(
            nn.Conv2d(in_channels, base_channels, 7, stride=2, padding=3),
            nn.BatchNorm2d(base_channels),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1)
        )
        
        # æ®‹å·®é˜¶æ®µ
        self.stage1 = self._make_stage(base_channels, base_channels, num_blocks[0])
        self.stage2 = self._make_stage(base_channels, base_channels * 2, num_blocks[1], stride=2)
        self.stage3 = self._make_stage(base_channels * 2, base_channels * 4, num_blocks[2], stride=2)
        self.stage4 = self._make_stage(base_channels * 4, base_channels * 8, num_blocks[3], stride=2)
    
    def _make_stage(self, in_channels, out_channels, num_blocks, stride=1):
        """åˆ›å»ºæ®‹å·®é˜¶æ®µ"""
        layers = []
        
        # ç¬¬ä¸€ä¸ªå—å¤„ç†ä¸‹é‡‡æ ·
        layers.append(ResidualBlock(in_channels, out_channels, stride))
        
        # åç»­å—
        for _ in range(1, num_blocks):
            layers.append(ResidualBlock(out_channels, out_channels))
        
        return nn.Sequential(*layers)
    
    def forward(self, x):
        # Stem
        x = self.stem(x)
        
        # æ®‹å·®é˜¶æ®µ
        x1 = self.stage1(x)  # /4
        x2 = self.stage2(x1) # /8
        x3 = self.stage3(x2) # /16
        x4 = self.stage4(x3) # /32
        
        return x4  # è¿”å›æœ€ç»ˆç‰¹å¾å›¾

class ResidualBlock(nn.Module):
    """æ®‹å·®å—"""
    
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # æ·å¾„è¿æ¥
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        residual = x
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        out += self.shortcut(residual)
        out = self.relu(out)
        
        return out

class MultiScaleFusion(nn.Module):
    """å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å—"""
    
    def __init__(self, channel_list, out_channels):
        super().__init__()
        
        self.channel_list = channel_list
        self.num_scales = len(channel_list)
        
        # ç‰¹å¾æŠ•å½±å±‚
        self.projections = nn.ModuleList()
        for channels in channel_list:
            proj = nn.Sequential(
                nn.Conv2d(channels, out_channels, 1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            )
            self.projections.append(proj)
        
        # ç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = SpatialAttention(out_channels)
        
        # é€šé“æ³¨æ„åŠ›
        self.channel_attention = ChannelAttention(out_channels)
    
    def forward(self, features_list):
        """
        èåˆå¤šå°ºåº¦ç‰¹å¾
        
        å‚æ•°:
            features_list: å¤šå°ºåº¦ç‰¹å¾åˆ—è¡¨ [feat1, feat2, feat3]
        """
        batch_size = features_list[0].shape[0]
        
        # ä¸Šé‡‡æ ·åˆ°æœ€å¤§å°ºåº¦
        target_size = features_list[0].shape[-2:]
        aligned_features = []
        
        for i, feat in enumerate(features_list):
            # æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦
            proj_feat = self.projections[i](feat)
            
            # ä¸Šé‡‡æ ·åˆ°ç›®æ ‡å°ºå¯¸
            if proj_feat.shape[-2:] != target_size:
                proj_feat = F.interpolate(proj_feat, size=target_size, 
                                        mode='bilinear', align_corners=False)
            
            aligned_features.append(proj_feat)
        
        # ç‰¹å¾æ‹¼æ¥
        concat_features = torch.cat(aligned_features, dim=1)
        
        # ç©ºé—´æ³¨æ„åŠ›
        spatial_weights = self.spatial_attention(concat_features)
        
        # é€šé“æ³¨æ„åŠ›
        channel_weights = self.channel_attention(concat_features)
        
        # åŠ æƒèåˆ
        weighted_features = []
        for i, feat in enumerate(aligned_features):
            weighted = feat * spatial_weights * channel_weights[:, i:i+1, :, :]
            weighted_features.append(weighted)
        
        # æœ€ç»ˆèåˆ
        fused = torch.stack(weighted_features, dim=1).mean(dim=1)
        
        return fused

class SpatialAttention(nn.Module):
    """ç©ºé—´æ³¨æ„åŠ›æ¨¡å—"""
    
    def __init__(self, in_channels):
        super().__init__()
        
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels * 3, in_channels, 3, padding=1),
            nn.BatchNorm2d(in_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels, 1, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        attention = self.conv(x)
        return attention

class ChannelAttention(nn.Module):
    """é€šé“æ³¨æ„åŠ›æ¨¡å—"""
    
    def __init__(self, in_channels):
        super().__init__()
        
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(in_channels * 3, in_channels * 3 // 16),
            nn.ReLU(inplace=True),
            nn.Linear(in_channels * 3 // 16, 3),  # 3ä¸ªå°ºåº¦
            nn.Softmax(dim=1)
        )
    
    def forward(self, x):
        batch_size, channels, height, width = x.shape
        
        # å…¨å±€å¹³å‡æ± åŒ–
        gap = self.avg_pool(x).view(batch_size, channels)
        
        # é€šé“æƒé‡
        weights = self.fc(gap).view(batch_size, 3, 1, 1)
        
        return weights

class GaussianBlur(nn.Module):
    """é«˜æ–¯æ¨¡ç³Šå±‚"""
    
    def __init__(self, sigma