---
tags:
  - code
  - deepfake
  - å¯¹æ¯”å­¦ä¹ 
aliases:
---
[[å®éªŒæ–¹æ¡ˆä¸ä»£ç å®ç°ï¼šR-INE æ®‹å·®ä¸åŒæ¨¡å¼æ£€æµ‹]]
[[æ·±åº¦ä¼ªé€ æ£€æµ‹-å›¾åƒå¯¹å¯¹æ¯”å­¦ä¹ ç ”ç©¶æ–¹æ¡ˆ]]
# ğŸ§¬ å®Œæ•´æ¨¡å‹å®ç°ï¼šDeepfakeContrastiveResidual

#deepfake-detection #pytorch #model-architecture #contrastive-residual

## ğŸ—ï¸ æ¨¡å—åŒ–è®¾è®¡è¯´æ˜

ä¸ºäº†ä¿è¯ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§ï¼Œæˆ‘ä»¬å°†æ¨¡å‹æ‹†åˆ†ä¸ºä»¥ä¸‹ç‹¬ç«‹æ¨¡å—ï¼š

>1. **`FeatureExtractor`**: éª¨å¹²ç½‘ç»œï¼ˆBackboneï¼‰ï¼Œè´Ÿè´£å°†å›¾åƒè½¬æ¢ä¸ºç‰¹å¾å‘é‡ã€‚
>2. **`MemoryBank`**: è®°å¿†åº“ï¼Œç”¨äºå­˜å‚¨çœŸå®æ ·æœ¬çš„åŸå‹ç‰¹å¾ï¼Œæ”¯æŒå†™å…¥å’Œæ£€ç´¢ã€‚
>3. **`DifferenceAttention`**: å·®å¼‚æ³¨æ„åŠ›æ¨¡å—ï¼Œèåˆç‰¹å¾ä¸å·®å¼‚ä¿¡æ¯ã€‚
>4. **`ResidualHead`**: æ®‹å·®æ£€æµ‹å¤´ï¼Œä¸“é—¨æ ¹æ®ç‰¹å¾è·ç¦»åˆ¤æ–­æ˜¯å¦å¼‚å¸¸ã€‚
>5. **`DeepfakeContrastiveResidual`**: ä¸»æ¨¡å‹ï¼Œç»Ÿç­¹åŒæ¨¡å¼ï¼ˆPair/Singleï¼‰é€»è¾‘ã€‚

    

---

## ğŸ’» PyTorch ä»£ç å®ç°

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models

# ==========================================
# 1. ç‰¹å¾æå–å™¨æ¨¡å— (Feature Extractor)
# ==========================================

-> é‡å†™é€‚é…rine
class FeatureExtractor(nn.Module):
    """
    éª¨å¹²ç½‘ç»œæ¨¡å—
    é»˜è®¤ä½¿ç”¨ ResNet50ï¼Œå¯æ›¿æ¢ä¸º R-INE æˆ– EfficientNetã€‚
    å»é™¤æœ€åçš„å…¨è¿æ¥åˆ†ç±»å±‚ï¼Œåªè¾“å‡ºç‰¹å¾å‘é‡ã€‚
    """
    def __init__(self, backbone_name='resnet50', pretrained=True):
        super().__init__()
        if backbone_name == 'resnet50':
            # åŠ è½½é¢„è®­ç»ƒçš„ ResNet50
            base_model = models.resnet50(pretrained=pretrained)
            # ç§»é™¤æœ€åçš„ fc å±‚
            self.backbone = nn.Sequential(*list(base_model.children())[:-1])
            self.output_dim = 2048 # ResNet50 çš„è¾“å‡ºç»´åº¦
        else:
            raise NotImplementedError(f"Backbone {backbone_name} not implemented yet.")
            
    def forward(self, x):
        # Input: [B, 3, 224, 224]
        features = self.backbone(x)
        # Flatten: [B, 2048, 1, 1] -> [B, 2048]
        return torch.flatten(features, 1)

# ==========================================
# 2. è®°å¿†åº“æ¨¡å— (Memory Bank)
# ==========================================
è¿™ä¸€å—çš„è®°å¿†åº“éœ€è¦é‡å†™ -> è¯•è¯•ä½¿ç”¨moca
class MemoryBank(nn.Module):
    """
    è®°å¿†åº“ç³»ç»Ÿ
    ç”¨äºå­˜å‚¨çœŸå®æ ·æœ¬(Real)çš„ç‰¹å¾åŸå‹ã€‚
    åœ¨æ¨ç†(Single Mode)æ—¶ï¼Œæ£€ç´¢æœ€ç›¸ä¼¼çš„çœŸå®ç‰¹å¾ä½œä¸º'åŸºå‡†'ã€‚
    """
    def __init__(self, feature_dim, bank_size=1024, momentum=0.9):
        super().__init__()
        self.feature_dim = feature_dim
        self.bank_size = bank_size
        self.momentum = momentum
        
        # æ³¨å†Œç¼“å†²åŒº (ä¸å‚ä¸æ¢¯åº¦æ›´æ–°ï¼Œä½†ä¼šéšæ¨¡å‹ä¿å­˜)
        # åˆå§‹åŒ–ä¸ºéšæœºæ­£æ€åˆ†å¸ƒå¹¶å½’ä¸€åŒ–
        self.register_buffer('features', torch.randn(bank_size, feature_dim))
        self.register_buffer('ptr', torch.zeros(1, dtype=torch.long))
        self.features = F.normalize(self.features, dim=1)
        
    def update(self, keys):
        """
        æ›´æ–°è®°å¿†åº“ (é€šå¸¸åœ¨è®­ç»ƒé˜¶æ®µå¤„ç†çœŸå®æ ·æœ¬æ—¶è°ƒç”¨)
        keys: [B, Dim]
        """
        with torch.no_grad():
            batch_size = keys.shape[0]
            ptr = int(self.ptr)
            
            # å½’ä¸€åŒ–ç‰¹å¾
            keys = F.normalize(keys, dim=1)
            
            # å¤„ç†è¾¹ç•Œæƒ…å†µï¼šå¦‚æœ batch è¶…è¿‡å‰©ä½™ç©ºé—´ï¼Œåˆ™æˆªæ–­æˆ–å¾ªç¯è¦†ç›–
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šç›´æ¥è¦†ç›–ï¼Œè‹¥è¶Šç•Œåˆ™å›åˆ°å¤´éƒ¨
            if ptr + batch_size > self.bank_size:
                batch_size = self.bank_size - ptr # åªå¡«æ»¡å‰©ä½™éƒ¨åˆ†
                keys = keys[:batch_size]
            
            # åŠ¨é‡æ›´æ–°æˆ–ç›´æ¥æ›¿æ¢ (æ­¤å¤„é‡‡ç”¨ç›´æ¥æ›¿æ¢ç”¨äºæ„å»ºåŸå‹)
            self.features[ptr:ptr+batch_size] = keys
            
            # æ›´æ–°æŒ‡é’ˆ
            self.ptr[0] = (ptr + batch_size) % self.bank_size

    def retrieve(self, query):
        """
        æ£€ç´¢æœ€ç›¸ä¼¼ç‰¹å¾
        query: [B, Dim]
        Return: [B, Dim] (ä¸ query æœ€ç›¸ä¼¼çš„ memory feature)
        """
        # å½’ä¸€åŒ–æŸ¥è¯¢
        query = F.normalize(query, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦: [B, Dim] @ [Dim, Bank] -> [B, Bank]
        sim = torch.mm(query, self.features.t())
        
        # æ‰¾åˆ°ç›¸ä¼¼åº¦æœ€é«˜çš„ç´¢å¼•
        best_sim_idx = sim.argmax(dim=1)
        
        # å–å‡ºå¯¹åº”çš„ç‰¹å¾
        retrieved_feats = self.features[best_sim_idx] # [B, Dim]
        
        return retrieved_feats

# ==========================================
# 3. å·®å¼‚æ³¨æ„åŠ›ä¸èåˆ (Difference Attention)
# ==========================================
class DifferenceAttention(nn.Module):
    """
    æ ¸å¿ƒç»„ä»¶ï¼šè®¡ç®—äº¤å‰æ³¨æ„åŠ›
    åˆ©ç”¨ 'å·®å¼‚ä¿¡æ¯' æ¥å¢å¼º 'åŸå§‹ç‰¹å¾'ï¼Œä½¿æ¨¡å‹å…³æ³¨ç¯¡æ”¹åŒºåŸŸã€‚
    """
    def __init__(self, feature_dim, hidden_dim=512):
        super().__init__()
        # é™ç»´å¤„ç†ï¼Œå‡å°‘è®¡ç®—é‡
        self.query_layer = nn.Linear(feature_dim, hidden_dim)
        self.key_layer = nn.Linear(feature_dim, hidden_dim)
        self.value_layer = nn.Linear(feature_dim, hidden_dim)
        
        # èåˆåçš„æ¢å¤å±‚
        self.out_layer = nn.Linear(hidden_dim, feature_dim)
        self.scale = hidden_dim ** -0.5
        
        # é—¨æ§æœºåˆ¶ (å¯é€‰)
        self.gate = nn.Sequential(
            nn.Linear(feature_dim * 2, feature_dim),
            nn.Sigmoid()
        )

    def forward(self, original_feat, difference_feat):
        """
        Args:
            original_feat: åŸå§‹å›¾åƒç‰¹å¾ (Query)
            difference_feat: å·®å¼‚ç‰¹å¾ (Key/Value) - æ¥è‡ª Pair æˆ– Memory å·®åˆ†
        """
        # Q, K, V
        Q = self.query_layer(original_feat).unsqueeze(1)    # [B, 1, H]
        K = self.key_layer(difference_feat).unsqueeze(1)    # [B, 1, H]
        V = self.value_layer(difference_feat).unsqueeze(1)  # [B, 1, H]
        
        # Attention Score
        attn = (Q @ K.transpose(-2, -1)) * self.scale
        attn = attn.softmax(dim=-1) # [B, 1, 1] å®é™…ä¸Šæ˜¯æ ‡é‡æƒé‡
        
        # åŠ æƒèåˆ
        context = (attn @ V).squeeze(1) # [B, H]
        context = self.out_layer(context) # [B, Dim]
        
        # æ®‹å·®è¿æ¥ + ç®€å•çš„é—¨æ§èåˆ
        # ç»“åˆåŸå§‹ç‰¹å¾å’Œæ³¨æ„åŠ›ä¸Šä¸‹æ–‡
        fused = original_feat + context
        return fused

# ==========================================
# 4. æ®‹å·®æ£€æµ‹å¤´ (Residual Head)
# ==========================================
class ResidualHead(nn.Module):
    """
    ä¸“é—¨ç”¨äºåˆ¤æ–­ 'æ‰°åŠ¨é¡¹' å¤§å°çš„è¾…åŠ©å¤´ã€‚
    å¦‚æœå·®å¼‚å¾ˆå¤§ï¼Œè¯´æ˜å¤§æ¦‚ç‡æ˜¯ Deepfakeï¼›å¦‚æœå¾ˆå°ï¼Œå¯èƒ½æ˜¯çœŸå®å›¾ç‰‡ä¹‹é—´çš„è‡ªç„¶å·®å¼‚ã€‚
    """
    def __init__(self, feature_dim):
        super().__init__()
        self.head = nn.Sequential(
            nn.Linear(feature_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 1),
            nn.Sigmoid() # è¾“å‡º 0-1 ä¹‹é—´çš„å¼‚å¸¸åˆ†æ•°
        )
        
    def forward(self, difference_feat):
        # è¾“å…¥å·®å¼‚å‘é‡ï¼Œè¾“å‡ºå¼‚å¸¸åˆ†æ•°
        return self.head(difference_feat)

# ==========================================
# 5. å®Œæ•´æ¨¡å‹ä¸»ç±» (Main Model)
# ==========================================
class DeepfakeContrastiveResidual(nn.Module):
    """
    Deepfake Contrastive Residual Network (DCR-Net)
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. mode='pair': è®­ç»ƒæ—¶ä½¿ç”¨ã€‚è¾“å…¥ (Img, Img_Pair)ï¼Œæ˜¾å¼è®¡ç®—å·®å¼‚ã€‚
    2. mode='single': æ¨ç†æ—¶ä½¿ç”¨ã€‚è¾“å…¥ (Img)ï¼Œä» Memory Bank æ£€ç´¢åŸºå‡†è®¡ç®—å·®å¼‚ã€‚
    """
    def __init__(self, feature_dim=2048, memory_size=2048):
        super().__init__()
        
        # 1. éª¨å¹²ç½‘ç»œ
        self.backbone = FeatureExtractor(backbone_name='resnet50')
        
        # 2. è®°å¿†åº“
        self.memory_bank = MemoryBank(feature_dim, bank_size=memory_size)
        
        # 3. èåˆæ¨¡å—
        self.fusion = DifferenceAttention(feature_dim)
        
        # 4. ä¸¤ä¸ªæ£€æµ‹å¤´
        # ä¸»åˆ†ç±»å¤´ (Real vs Fake)
        self.classifier = nn.Linear(feature_dim, 2)
        # è¾…åŠ©æ®‹å·®å¤´ (Anomaly Score)
        self.residual_head = ResidualHead(feature_dim)
        
    def forward(self, x, x_pair=None, mode='single'):
        """
        å‰å‘ä¼ æ’­é€»è¾‘
        
        Args:
            x: ä¸»è¾“å…¥å›¾åƒ [B, 3, 224, 224]
            x_pair: é…å¯¹å›¾åƒ (ä»… mode='pair' æ—¶éœ€è¦)
            mode: 'pair' | 'single' | 'update_memory'
        
        Returns:
            logits: åˆ†ç±»åˆ†æ•° [B, 2]
            anomaly_score: æ®‹å·®å¼‚å¸¸åˆ†æ•° [B, 1]
            features: æœ€ç»ˆç”¨äºåˆ†ç±»çš„ç‰¹å¾ [B, Dim] (ç”¨äºå¯è§†åŒ–)
        """
        # 1. æå–ä¸»å›¾åƒç‰¹å¾
        feat = self.backbone(x) # [B, 2048]
        
        difference_feat = None
        
        # ================== æ¨¡å¼åˆ†æ”¯ ==================
        if mode == 'update_memory':
            # ç‰¹æ®Šæ¨¡å¼ï¼šä»…ç”¨äºæ›´æ–°è®°å¿†åº“ (è¾“å…¥å¿…é¡»æ˜¯çœŸå®å›¾åƒ)
            self.memory_bank.update(feat)
            return None
            
        elif mode == 'pair' and x_pair is not None:
            # === è®­ç»ƒæ¨¡å¼ (Contrastive) ===
            # æå–é…å¯¹å›¾åƒç‰¹å¾
            feat_pair = self.backbone(x_pair)
            
            # è®¡ç®—çœŸå®å·®å¼‚ (Feature Space Diff)
            # ä½¿ç”¨ abs å·®åˆ†ä¿ç•™å¹…åº¦ä¿¡æ¯
            difference_feat = torch.abs(feat - feat_pair)
            
        else: # mode == 'single' or x_pair is None
            # === æ¨ç†/å•æ ·æœ¬æ¨¡å¼ (Inference) ===
            if self.training:
                # å¦‚æœåœ¨è®­ç»ƒæ—¶æ„å¤–è¿›å…¥å•æ¨¡å¼ï¼Œè­¦å‘Šæˆ–ä½¿ç”¨è‡ªèº«ä½œä¸ºåŸºå‡†(ä¸æ¨è)
                pass 
            
            # 1. ä»è®°å¿†åº“æ£€ç´¢æœ€è¿‘çš„â€œçœŸå®åŸå‹â€
            # retrieved_feat ç›¸å½“äºâ€œæ¨æµ‹çš„è¯¥å›¾çœŸå®æ ·å­â€
            retrieved_feat = self.memory_bank.retrieve(feat)
            
            # 2. è®¡ç®—è™šæ‹Ÿå·®å¼‚ (Virtual Residual)
            difference_feat = torch.abs(feat - retrieved_feat)
        
        # ================== èåˆä¸è¾“å‡º ==================
        
        # 1. è¾…åŠ©ä»»åŠ¡ï¼šé€šè¿‡æ®‹å·®å¤´åˆ¤æ–­å¼‚å¸¸ç¨‹åº¦
        # ç†è®ºä¸Šï¼šç¯¡æ”¹å›¾çš„ difference_feat åº”è¯¥å¾ˆå¤§ï¼ŒçœŸå®å›¾åº”è¯¥å¾ˆå°
        anomaly_score = self.residual_head(difference_feat)
        
        # 2. äº¤å‰æ³¨æ„åŠ›èåˆ
        # è®©æ¨¡å‹æ ¹æ®å·®å¼‚å›¾ï¼Œå»åŠ å¼ºåŸå§‹ç‰¹å¾ä¸­çš„ä¼ªé€ ç—•è¿¹
        enhanced_feat = self.fusion(feat, difference_feat)
        
        # 3. æœ€ç»ˆåˆ†ç±»
        logits = self.classifier(enhanced_feat)
        
        return logits, anomaly_score, enhanced_feat

# ==========================================
# 6. ä½¿ç”¨ç¤ºä¾‹ (Example Usage)
# ==========================================
if __name__ == "__main__":
    # å®ä¾‹åŒ–æ¨¡å‹
    model = DeepfakeContrastiveResidual(feature_dim=2048)
    
    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    batch_size = 4
    real_imgs = torch.randn(batch_size, 3, 224, 224) # çœŸå®å›¾
    fake_imgs = torch.randn(batch_size, 3, 224, 224) # ç¯¡æ”¹å›¾
    
    print("--- 1. è®°å¿†åº“é¢„çƒ­ (Warmup) ---")
    # å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›çœŸå®å›¾ç‰‡ç”¨äºæ„å»ºåŸºå‡†
    model.eval()
    model(real_imgs, mode='update_memory')
    print("Memory bank updated.")
    
    print("\n--- 2. è®­ç»ƒé˜¶æ®µ (Pair Mode) ---")
    model.train()
    # è¾“å…¥ï¼šçœŸå®å›¾ å’Œ å¯¹åº”çš„ä¼ªé€ å›¾
    logits, ano_score, _ = model(fake_imgs, x_pair=real_imgs, mode='pair')
    print(f"Logits shape: {logits.shape}")          # [4, 2]
    print(f"Anomaly Score shape: {ano_score.shape}") # [4, 1]
    
    print("\n--- 3. æ¨ç†é˜¶æ®µ (Single Mode) ---")
    model.eval()
    # è¾“å…¥ï¼šæœªçŸ¥å›¾åƒ (æ¨¡æ‹Ÿä¼ªé€ å›¾)
    # æ¨¡å‹ä¼šè‡ªåŠ¨å»è®°å¿†åº“æ‰¾æœ€åƒçš„çœŸå®ç‰¹å¾è¿›è¡Œå¯¹æ¯”
    logits_test, ano_score_test, _ = model(fake_imgs, mode='single')
    print(f"Inference Logits: {logits_test[0].detach().cpu().numpy()}")
    print(f"Inference Anomaly Score: {ano_score_test[0].item():.4f}")
```

---

## ğŸ’¡ å…³é”®å®ç°ç»†èŠ‚æ³¨é‡Š

1. **`MemoryBank` çš„è®¾è®¡**ï¼š
    
    - **Buffer æœºåˆ¶**ï¼šä½¿ç”¨äº† `register_buffer`ã€‚è¿™æ„å‘³ç€ `memory` çŸ©é˜µæ˜¯æ¨¡å‹çŠ¶æ€çš„ä¸€éƒ¨åˆ†ï¼ˆä¿å­˜ PTH æ–‡ä»¶æ—¶ä¼šå¸¦ä¸Šï¼‰ï¼Œä½†åœ¨åå‘ä¼ æ’­æ—¶**ä¸ä¼šè®¡ç®—æ¢¯åº¦**ã€‚
        
    - **æ›´æ–°ç­–ç•¥**ï¼šä»£ç ä¸­ä½¿ç”¨ç®€å•çš„ FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰æˆ–å¾ªç¯è¦†ç›–ã€‚åœ¨å®é™…å¤§è§„æ¨¡è®­ç»ƒä¸­ï¼Œé€šå¸¸ä¼šåœ¨æ¯ä¸ª Epoch ç»“æŸæ—¶ï¼Œç”¨æ•´ä¸ªè®­ç»ƒé›†çš„çœŸå®æ ·æœ¬ç‰¹å¾é‡æ–°æ„å»ºä¸€æ¬¡è®°å¿†åº“ã€‚
    - æˆ‘è§‰å¾—ä¸Šé¢è¯´çš„æ˜¯ä¸€å¨å±ï¼Œæ‰€ä»¥çœ‹ä¸‹é¢è¿™ä¸ªï¼š[[memory bank å®ç°æ–¹æ¡ˆ]]
        
2. **`DifferenceAttention` çš„é€»è¾‘**ï¼š
    
    - è¿™é‡Œä½¿ç”¨äº† `Query` (åŸå›¾ç‰¹å¾) å’Œ `Key/Value` (å·®å¼‚ç‰¹å¾)ã€‚
        
    - **ç‰©ç†å«ä¹‰**ï¼šæ¨¡å‹åœ¨é—®ï¼šâ€œåŸºäºæˆ‘å½“å‰çš„ç‰¹å¾ï¼ˆQueryï¼‰ï¼Œå·®å¼‚éƒ¨åˆ†ï¼ˆKeyï¼‰ä¸­æœ€æ˜¾è‘—çš„ä¿¡æ¯æ˜¯ä»€ä¹ˆï¼Ÿâ€ç„¶åå°†è¿™äº›æ˜¾è‘—çš„å·®å¼‚ä¿¡æ¯ï¼ˆValueï¼‰åŠ å›åˆ°åŸç‰¹å¾ä¸­ã€‚è¿™èƒ½å¸®åŠ©åˆ†ç±»å™¨èšç„¦äºâ€œå› ç¯¡æ”¹è€Œäº§ç”Ÿå·®å¼‚â€çš„é€šé“ã€‚
        
3. **`mode` çš„åˆ‡æ¢**ï¼š
    
    - è®­ç»ƒæ—¶ï¼Œä½ æœ‰ Ground Truth çš„é…å¯¹æ•°æ®ï¼Œæ‰€ä»¥ç”¨ `mode='pair'` å¼ºè¡Œæ•™ä¼šæ¨¡å‹â€œä»€ä¹ˆæ˜¯å·®å¼‚â€ã€‚
        
    - æ¨ç†æ—¶ï¼Œæ²¡æœ‰é…å¯¹æ•°æ®ï¼Œæ¨¡å‹é€šè¿‡ `mode='single'` ä¾èµ–è®°å¿†åº“æ¥â€œå›å¿†â€æ­£å¸¸çš„ç‰¹å¾é•¿ä»€ä¹ˆæ ·ï¼Œä»è€Œæ¨¡æ‹Ÿå‡ºå·®å¼‚ã€‚
        

## ğŸ“ Next Step

ä½ å¯ä»¥å°†æ­¤ä»£ç ä¿å­˜ä¸º model.pyã€‚

ä¸‹ä¸€æ­¥å»ºè®®ï¼šç¼–å†™ä¸€ä¸ªè‡ªå®šä¹‰çš„ LossFunctionï¼Œéœ€è¦ç»„åˆï¼š

1. `CrossEntropyLoss` (é’ˆå¯¹ logits)
    
2. `BCELoss` (é’ˆå¯¹ anomaly_scoreï¼ŒçœŸå®å›¾pairæ ‡ç­¾ä¸º0ï¼Œä¼ªé€ å›¾pairæ ‡ç­¾ä¸º1)
    
3. `ContrastiveLoss` (é’ˆå¯¹ç‰¹å¾è·ç¦»)

